{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ea25199-8d3b-4e1e-81de-6d1f610705ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VFEOskzhhbc?si=04NY5hpGlPKxElGi\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VFEOskzhhbc?si=04NY5hpGlPKxElGi\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6fe243b-39cc-42b7-9c19-bbc04fca6196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d287f81-3d92-4b02-86c7-0ed9bb0419c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_numbers = [21, 22, -108, 31, -1, 32, 34, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5a1ea0-1d45-43ad-a9fc-0f97ff474528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0213b6b9-d088-4bfe-baa9-bc097b60236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccede4c7-02e4-4cd6-bb0e-5a1e25f632c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.take(3):\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37efbf81-1d7a-4ccc-b07a-e10a4a5ff22c",
   "metadata": {},
   "source": [
    "# remove negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db633b5-54d3-410a-821d-5d83e6146902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.filter(lambda x: x>0)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02449de6-c96c-4aa0-aa57-3974f2d00363",
   "metadata": {},
   "source": [
    "# convert values into something else\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeec2fe7-fb81-4cef-9c15-fc9da0ef9b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512\n",
      "1584\n",
      "2232\n",
      "2304\n",
      "2448\n",
      "2232\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.map(lambda x: x*72)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fba6b16-742e-4a33-aa30-373e6e1d4c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304\n",
      "2232\n",
      "2448\n",
      "1512\n",
      "2232\n",
      "1584\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.shuffle(3)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe7b26-0e97-4d2e-8b68-6782c4d557b6",
   "metadata": {},
   "source": [
    "# batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6217c3ca-6feb-42ab-a42e-dfb9004703ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1512 2448 2304]\n",
      "[1584 2232 2232]\n"
     ]
    }
   ],
   "source": [
    "for sales_batch in tf_dataset.batch(3):\n",
    "    print(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbca50b-5010-4ec0-8224-bbc750f93ff7",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3db48d0-091d-4410-9714-87d3039e2e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1512 2232]\n",
      "[2448 2232]\n",
      "[2304 1584]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "\n",
    "tf_dataset = tf_dataset.filter(lambda x: x>0).map(lambda y: y*72).shuffle(3).batch(2)\n",
    "\n",
    "for sales in tf_dataset:\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7da75a02-3abc-4cc3-8000-9cf3bb20cd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2232 1584]\n",
      "[1512 2448]\n",
      "[2232 2304]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers).filter(lambda x: x>0).map(lambda y: y*72).shuffle(3).batch(2)\n",
    "\n",
    "for sales in tf_dataset:\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdde5110-2439-49e6-9365-ece2a03110b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\00tb-cats1-mediumSquareAt3X.jpg'\n",
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\07CAT-STRIPES-mediumSquareAt3X-v2.jpg'\n",
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\0_c_scale,w_400_ncom_en_US_games_switch_c_cat-switch_.jpg'\n",
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\1200px-Cat03.jpg'\n",
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\1200px-RedCat_8727.jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = tf.data.Dataset.list_files('C:/Users/Public/lmaaya/data/DeepLearning/datasets/cats_dogs/*/*', shuffle=False)\n",
    "\n",
    "for file in images_ds.take(5):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "197c6314-e0e1-4843-93cb-af365338cac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\cat (2).jpg'\n",
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\iStock-1419313949.jpg'\n",
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\459409892.jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = images_ds.shuffle(200)\n",
    "\n",
    "for file in images_ds.take(3):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "599c8acf-d208-4733-a54a-de4754dfd391",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['cat', 'dog']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f18366-18a6-4a6b-9b24-8bf6c8313fe6",
   "metadata": {},
   "source": [
    "# Split and train in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b55cfd9c-fbe6-4e89-9df3-180e03f3fbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(images_ds)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9fca1e2-3cbd-43a2-993f-7ce1c504022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(image_count*0.8)\n",
    "\n",
    "train_ds  = images_ds.take(train_size)\n",
    "test_ds = images_ds.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e211456-bafe-49d4-94d9-ed1b4eb7e658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 59)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8150c56-ee69-4d79-b4c2-5c36d50fe61a",
   "metadata": {},
   "source": [
    "# extract labels from the images using split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2464afe-bbc0-4cfb-989d-8196d8f12ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cats'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\459409892.jpg'\n",
    "\n",
    "s.split(\"\\\\\")[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1586968-4d23-42d9-b818-b2a07e5c7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    import os\n",
    "    return tf.strings.split(file_path, os.path.sep)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dd884b9-7d60-4844-8b64-13007682b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path):\n",
    "    label = get_label(file_path)\n",
    "    \n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bfe9804-d47c-4397-980b-2a76639e2c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\07CAT-STRIPES-mediumSquareAt3X-v2.jpg'\n",
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\shutterstock_266645570.jpg'\n",
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\GettyImages-638711214-58946e6d3df78caebc8f6da3.jpg'\n",
      "b'C:\\\\Users\\\\Public\\\\lmaaya\\\\data\\\\DeepLearning\\\\datasets\\\\cats_dogs\\\\cats\\\\cat-1.jpg'\n"
     ]
    }
   ],
   "source": [
    "for t in train_ds.take(4):\n",
    "    print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6636f5e-8ae4-4d82-9e17-27330fb5995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  tf.Tensor(\n",
      "[[[191.       164.       135.      ]\n",
      "  [193.       166.       137.      ]\n",
      "  [192.25     165.25     136.25    ]\n",
      "  ...\n",
      "  [199.83008  172.58008  146.33008 ]\n",
      "  [200.       172.       148.      ]\n",
      "  [198.       170.       146.      ]]\n",
      "\n",
      " [[191.       164.       135.      ]\n",
      "  [193.       166.       137.      ]\n",
      "  [192.25     165.25     136.25    ]\n",
      "  ...\n",
      "  [200.51953  173.26953  147.01953 ]\n",
      "  [198.       170.       146.      ]\n",
      "  [198.       170.       146.      ]]\n",
      "\n",
      " [[191.       164.       135.      ]\n",
      "  [191.39844  164.39844  135.39844 ]\n",
      "  [191.24902  164.24902  135.24902 ]\n",
      "  ...\n",
      "  [199.75098  172.50098  146.25098 ]\n",
      "  [200.34863  172.34863  148.34863 ]\n",
      "  [198.80078  170.80078  146.80078 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 66.74609   54.148438  30.347656]\n",
      "  [ 61.293945  50.14453   28.644531]\n",
      "  [ 57.69336   49.095703  29.496094]\n",
      "  ...\n",
      "  [ 86.55371   72.35254   53.35254 ]\n",
      "  [ 85.40039   70.59863   53.69922 ]\n",
      "  [ 83.90039   68.25      51.5     ]]\n",
      "\n",
      " [[ 63.16504   50.68457   34.2041  ]\n",
      "  [ 60.14258   48.532227  33.441406]\n",
      "  [ 58.652344  48.152344  30.66211 ]\n",
      "  ...\n",
      "  [ 62.529297  52.808594  35.708008]\n",
      "  [ 65.18848   55.10742   39.506836]\n",
      "  [ 61.012695  50.57129   35.09082 ]]\n",
      "\n",
      " [[ 61.098633  49.938477  32.25879 ]\n",
      "  [ 59.708008  50.708008  34.02832 ]\n",
      "  [ 55.77832   44.52832   28.358398]\n",
      "  ...\n",
      "  [ 96.978516  80.61914   61.09961 ]\n",
      "  [ 95.4082    80.80859   60.40918 ]\n",
      "  [ 91.81836   77.21875   56.819336]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label:  tf.Tensor(b'cats', shape=(), dtype=string)\n",
      "Image:  tf.Tensor(\n",
      "[[[108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  ...\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]]\n",
      "\n",
      " [[108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  ...\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]]\n",
      "\n",
      " [[108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  ...\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  ...\n",
      "  [107.22803 163.77197 157.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]]\n",
      "\n",
      " [[108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  ...\n",
      "  [108.61182 162.60693 158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]]\n",
      "\n",
      " [[108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  ...\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]\n",
      "  [108.      163.      158.     ]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label:  tf.Tensor(b'cats', shape=(), dtype=string)\n",
      "Image:  tf.Tensor(\n",
      "[[[155.59766 144.59766 125.49609]\n",
      "  [164.95514 152.95514 138.95514]\n",
      "  [192.81277 179.96121 170.5159 ]\n",
      "  ...\n",
      "  [209.42941 193.42941 177.42941]\n",
      "  [208.      191.      171.     ]\n",
      "  [210.      190.      166.     ]]\n",
      "\n",
      " [[159.4961  148.14844 130.84375]\n",
      "  [166.40518 154.40518 140.40518]\n",
      "  [189.84683 177.84683 164.95786]\n",
      "  ...\n",
      "  [210.00864 194.00864 178.00864]\n",
      "  [208.      191.      171.     ]\n",
      "  [210.      190.      166.     ]]\n",
      "\n",
      " [[160.10547 148.10547 134.59766]\n",
      "  [166.28906 154.28906 138.28906]\n",
      "  [183.85547 172.10156 155.60938]\n",
      "  ...\n",
      "  [207.7539  191.7539  175.7539 ]\n",
      "  [207.53516 190.53516 170.53516]\n",
      "  [210.      190.      166.     ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[209.7539  184.89426 153.4732 ]\n",
      "  [211.7539  186.7539  156.7539 ]\n",
      "  [212.      186.      160.58087]\n",
      "  ...\n",
      "  [151.14844 144.14844 134.14844]\n",
      "  [153.      146.      136.     ]\n",
      "  [152.      145.      135.     ]]\n",
      "\n",
      " [[212.80173 188.80173 160.80173]\n",
      "  [216.65234 192.65234 166.65234]\n",
      "  [213.90317 188.90317 166.90317]\n",
      "  ...\n",
      "  [151.14844 144.14844 134.14844]\n",
      "  [153.      146.      136.     ]\n",
      "  [152.      145.      135.     ]]\n",
      "\n",
      " [[215.42969 190.42969 159.8789 ]\n",
      "  [213.28906 188.28906 157.73828]\n",
      "  [215.14844 190.14844 159.59766]\n",
      "  ...\n",
      "  [151.      147.      138.     ]\n",
      "  [151.      144.      136.     ]\n",
      "  [151.      144.      136.     ]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label:  tf.Tensor(b'cats', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(process_image)\n",
    "\n",
    "for img, label in train_ds.take(3):\n",
    "    print(\"Image: \", img)\n",
    "    print(\"Label: \", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d5272e7-e40b-4024-a462-6626da752d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    return image/255, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8dd990-2e00-4db4-b25a-5236695ee9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(scale)\n",
    "\n",
    "for image, label in train_ds.take(5):\n",
    "    print(\"**** Image: \", image.numpy()[0][0])\n",
    "    print(\"**** Label: \", label.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
